{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95cfb489",
   "metadata": {},
   "source": [
    "#### 관련용어\n",
    "  \n",
    " 1. 크롤링\n",
    " \n",
    " 크롤링(Crawling)이란, 웹을 탐색하는 컴퓨터 프로그램(크롤러)을 이용하여 여러 인터넷 사이트의 웹페이지 자료를 수집하여 분류하는 과정을 말함  \n",
    "   \n",
    " 2. 스크래핑\n",
    " \n",
    " 스크래핑(Scraping)이란, 웹사이트의 내용을 긁어다 원하는 형태로 가공하는 기술을 의미한다. 즉, 웹사이트의 데이터를 수집하는 모든 작업을 의미함  \n",
    "     \n",
    " 3. 파싱\n",
    " \n",
    " 파싱(Parsing)이란, 어떤 페이지(문서, html 등)에서 내가 원하는 데이터를 특정 패턴이나 순서로 추출하여 정보를 가공하는 것을 말함.  \n",
    " 예로 html소스를 문자열로 수집하여 html태그로 인식하도록 정보를 가공하여 html단위별 분석이 가능하게 구성할 수 있음    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ce433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request  # 웹에 통신 데이터를 요청하는 모듈\n",
    "from bs4 import BeautifulSoup\n",
    "'''\n",
    "## html source 가져오기(www.naver.com)\n",
    "url = 'https://www.naver.com'\n",
    "resp = urllib.request.urlopen(url)\n",
    "data = resp.read()\n",
    "\n",
    "## html 파싱(parsing)\n",
    "html = data.decode(\"utf-8\")     # byte -> 문서로 바꿈\n",
    "type(html)  # str\n",
    "soup = BeautifulSoup(html,\"html.parser\")    # html 문서를 html소스로 파싱\n",
    "\n",
    "## 태그 내용 가져오기\n",
    "# 1. h1태그 가져오기(find()메서드 사용과 직접참조)\n",
    "h1 = soup.find('h1')\n",
    "print(h1)\n",
    "print('-'*50)\n",
    "print(h1.a)\n",
    "print('-'*50)\n",
    "print(h1.a.string)\n",
    "\n",
    "# 2. find_all()\n",
    "h2s = soup.find_all('h2')\n",
    "type(h2)        # bs4.element.ResultSet 이지만 리스트형태이다!\n",
    "print(\"-\"*50)\n",
    "print(\"h2태그 문자열들을 출력\")\n",
    "for h2 in h2s:\n",
    "    print(h2.string)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03150e19",
   "metadata": {},
   "source": [
    "**문제**  \n",
    "www.naver.com에서 a태그 정보를 수집하고, 링크 문자열을 출력하는 코드를 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc583192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째,뉴스스탠드 바로가기\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "'''\n",
    "url = 'https://www.naver.com'\n",
    "resp = urllib.request.urlopen(url)\n",
    "data = resp.read()\n",
    "\n",
    "html = data.decode(\"utf-8\")\n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "\n",
    "## a태그 정보수집\n",
    "a_tags = soup.find('a')\n",
    "# print(f\"atags -- > \\n{a_tags}\")\n",
    "i = 0\n",
    "for tag in a_tags:\n",
    "    print(f\"{i}번째,{a_tags.string}\")\n",
    "    i+=1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url2 = 'https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=101'\n",
    "resp = urllib.request.urlopen(url2)\n",
    "data = resp.read()\n",
    "\n",
    "news = data.decode(\"euc-kr\")\n",
    "soup = BeautifulSoup(news,\"html.parser\")\n",
    "atags = soup.find_all('a')\n",
    "atags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0134b",
   "metadata": {},
   "source": [
    "#### 파일을 이용하여 html01.html을 읽어보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "'''\n",
    "# 주소를 모를때\n",
    "import os\n",
    "os.getcwd()\n",
    "## html01.html 파일읽기\n",
    "rfile = open('data/html01.html','r',encoding = 'utf8')\n",
    "html01 = rfile.read()\n",
    "\n",
    "# html 파싱\n",
    "source = BeautifulSoup(html01,'html.parser')\n",
    "\n",
    "# h1접근\n",
    "h1 = source.html.body.h1\n",
    "print(h1.string)\n",
    "\n",
    "## h2접근\n",
    "h2 = source.find('h2')\n",
    "print(\"h2 : \",h2.string)\n",
    "\n",
    "## body 접근 chlidren\n",
    "body = source.html.body\n",
    "print(\"body태그의 하위 태그들\")\n",
    "for i in body.children:\n",
    "    print(i)\n",
    "    \n",
    "## li태그들을 찾아서 출력하고, 내용을 출력\n",
    "li = source.find_all('li')\n",
    "idx = 0\n",
    "for l in li:\n",
    "    print(f\"li[{idx}] : {l.string}\")\n",
    "    idx +=1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca369cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 태그 속성 찾기\n",
    "\n",
    "# 파일읽기\n",
    "rfile2 = open(\"data/html02.html\",\"r\",encoding=\"utf8\")\n",
    "src2 = rfile2.read()\n",
    "\n",
    "html02 = BeautifulSoup(src2,\"html.parser\")\n",
    "\n",
    "# a 태그 찾기\n",
    "links = html02.find_all('a')  # a태그를 모두 찾기\n",
    "# print(\"links size = \",len(links))\n",
    "\n",
    "## a 태그에서 속성 찾기 : tag.attrs['속성']\n",
    "for link in links:\n",
    "    try:\n",
    "        # print(link)\n",
    "        # print(link.attrs['href'])\n",
    "        # print(link.attrs['target'])\n",
    "    except Exception as e:\n",
    "        # print(\"예외발생 : \",e)\n",
    "\n",
    "# 정규표현식으로 속성찾기\n",
    "import re\n",
    "# print(\"패턴 객체를 생성하여 속성 찾기\")\n",
    "patt = re.compile('https://')    # patt 객채\n",
    "# links = html02.find_all(href=patt)  # 패턴 찾기\n",
    "links = html02.find_all(target = '_blank')  # 패턴 찾기\n",
    "#print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69dbb20",
   "metadata": {},
   "source": [
    "#### 선택자를 이용한 정보수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a87412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## html03.html 파일읽기\n",
    "rfile3 = open('data/html03.html','r',encoding = 'utf8')\n",
    "src3 = rfile3.read()\n",
    "\n",
    "# html 파싱\n",
    "html3 = BeautifulSoup(src3,'html.parser')\n",
    "'''\n",
    "# 선택자를 이용한 내용 가져오기(select, select_one)\n",
    "# 1. id = 'tab' 선택자 정보 가져오기\n",
    "print(\">>>table 선택자<<<\")\n",
    "table = html3.select_one('#tab')    # table에 있는 id값 'tab'으로 접근\n",
    "print(table)\n",
    "\n",
    "# 2. id선택자와 계층구조\n",
    "print(\">>> 선택자 & 계층 <<<\")\n",
    "ths = html3.select('#tab > tr > th')\n",
    "print(ths)          # list형태로 반환\n",
    "\n",
    "# 3. class 선택자\n",
    "# print(\">>> class <<<\")\n",
    "trs = html3.select('#tab > .odd')\n",
    "# print(trs)\n",
    "\n",
    "# 4. 태그[속성=값] 찾기\n",
    "print(\">>> 속성값 <<<\")\n",
    "trs2 = html3.select(\"tr[class=odd]\")\n",
    "print(trs2)\n",
    "\n",
    "# 5. td 태그 내용\n",
    "print(\">>> tr > td 출력 <<<\")\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('td')\n",
    "    for td in tds:\n",
    "        print(td.string)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bcc846",
   "metadata": {},
   "source": [
    "#### 실습 : www.naver.com, www.daum.net, www.yahoo.com 에서 li태그 목록 정보 불러와 출력해보세요\n",
    "[추가] => new 중 하나를 선택해서 주요기사 내용을 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f357042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atags 수 =  6\n",
      "[오피셜] '박지성 없다' 본선 조 추첨에 참가할 레전드 명단 발표\n",
      "\n",
      "\n",
      "<div class=\"image_area\">\n",
      "<!-- [D] 썸네일 이미지 alt 값 비워주세요. -->\n",
      "<img alt=\"\" height=\"95\" onerror=\"imageOnError(this);\" src=\"https://dthumb-phinf.pstatic.net?src=http://imgnews.naver.net/image/139/2022/03/31/0002164871_001_20220331142701370.jpg&amp;type=nf160_95&amp;service=sports\" width=\"160\"/>\n",
      "</div>\n",
      "\n",
      "\n",
      "<div class=\"text_area\">\n",
      "<strong class=\"title\">[오피셜] '박지성 없다' 본선 조 추첨에 참가할 레전드 명단 발표</strong>\n",
      "<!-- [D] 내용 두줄 말줄임 적용해주세요. -->\n",
      "<p class=\"news\">\n",
      "\t\t\t\t\t\t\t\t[스포탈코리아] 곽힘찬 기자= 월드컵 본선 조 추첨이 이틀 앞으로 다가왔다. 조 추첨은 오는 4월 2일 새벽 1시(한국시간)에 진행된다.본선 진출국의 윤곽이...\n",
      "\t\t\t\t\t\t</p>\n",
      "<div class=\"information\">\n",
      "<span>스포탈코리아</span>\n",
      "<span>대표팀</span>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "\n",
      "KIA 양현종, 2년만에 개막전 선발…김민우·안우진도 영예\n",
      "\n",
      "\n",
      "<div class=\"image_area\">\n",
      "<!-- [D] 썸네일 이미지 alt 값 비워주세요. -->\n",
      "<img alt=\"\" height=\"95\" onerror=\"imageOnError(this);\" src=\"https://dthumb-phinf.pstatic.net?src=http://imgnews.naver.net/image/001/2022/03/31/PYH2022032210160005400_P4_20220331145623111.jpg&amp;type=nf160_95&amp;service=sports\" width=\"160\"/>\n",
      "</div>\n",
      "\n",
      "\n",
      "<div class=\"text_area\">\n",
      "<strong class=\"title\">KIA 양현종, 2년만에 개막전 선발…김민우·안우진도 영예</strong>\n",
      "<!-- [D] 내용 두줄 말줄임 적용해주세요. -->\n",
      "<p class=\"news\">\n",
      "\t\t\t\t\t\t\t\t키움은 12년 만에 개막전 선발로 토종 투수 택해두산 스탁, LG 플럿코, 롯데 반즈는 개막전서 KBO리그 정규시즌 데뷔양현종, 2년 만에 KBO리그 개막전...\n",
      "\t\t\t\t\t\t</p>\n",
      "<div class=\"information\">\n",
      "<span>연합뉴스</span>\n",
      "<span>KBO리그</span>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "\n",
      "'이적료 1590억→1033억'…맨유·토트넘·아스널 영입전 뛰어든다\n",
      "\n",
      "\n",
      "<div class=\"image_area\">\n",
      "<!-- [D] 썸네일 이미지 alt 값 비워주세요. -->\n",
      "<img alt=\"\" height=\"95\" onerror=\"imageOnError(this);\" src=\"https://dthumb-phinf.pstatic.net?src=http://imgnews.naver.net/image/477/2022/03/31/0000350202_001_20220331131202862.jpg&amp;type=nf160_95&amp;service=sports\" width=\"160\"/>\n",
      "</div>\n",
      "\n",
      "\n",
      "<div class=\"text_area\">\n",
      "<strong class=\"title\">'이적료 1590억→1033억'…맨유·토트넘·아스널 영입전 뛰어든다</strong>\n",
      "<!-- [D] 내용 두줄 말줄임 적용해주세요. -->\n",
      "<p class=\"news\">\n",
      "\t\t\t\t\t\t\t\t▲ 다윈 누네스[스포티비뉴스=이민재 기자] 벤피카의 다윈 누네스(22)에 대한 관심이 커지고 있다.영국 매체 '익스프레스'는 30일(한국 시간...\n",
      "\t\t\t\t\t\t</p>\n",
      "<div class=\"information\">\n",
      "<span>스포티비뉴스</span>\n",
      "<span>해외축구 일반</span>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "\n",
      "'맨유, 결심했다' 네덜란드 명장 선임 가속화…'위약금도 불사'\n",
      "\n",
      "\n",
      "<div class=\"image_area\">\n",
      "<!-- [D] 썸네일 이미지 alt 값 비워주세요. -->\n",
      "<img alt=\"\" height=\"95\" onerror=\"imageOnError(this);\" src=\"https://dthumb-phinf.pstatic.net?src=http://imgnews.naver.net/image/477/2022/03/31/0000350220_001_20220331141101891.jpg&amp;type=nf160_95&amp;service=sports\" width=\"160\"/>\n",
      "</div>\n",
      "\n",
      "\n",
      "<div class=\"text_area\">\n",
      "<strong class=\"title\">'맨유, 결심했다' 네덜란드 명장 선임 가속화…'위약금도 불사'</strong>\n",
      "<!-- [D] 내용 두줄 말줄임 적용해주세요. -->\n",
      "<p class=\"news\">\n",
      "\t\t\t\t\t\t\t\t▲ 맨체스터 유나이티드 차기 사령탑 후보, 에릭 텐 하흐 아약스 감독. ⓒ연합뉴스/EPA[스포티비뉴스=박건도 기자] 맨체스터 유나이티드가 차기 감독 선임에 ...\n",
      "\t\t\t\t\t\t</p>\n",
      "<div class=\"information\">\n",
      "<span>스포티비뉴스</span>\n",
      "<span>해외축구 일반</span>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "\n",
      "‘월드컵 조추첨 D-2’ 가상 결과는 어떨까? ‘한국 최악의 조’\n",
      "\n",
      "\n",
      "<div class=\"image_area\">\n",
      "<!-- [D] 썸네일 이미지 alt 값 비워주세요. -->\n",
      "<img alt=\"\" height=\"95\" onerror=\"imageOnError(this);\" src=\"https://dthumb-phinf.pstatic.net?src=http://imgnews.naver.net/image/382/2022/03/31/0000970238_001_20220331152401585.jpg&amp;type=nf160_95&amp;service=sports\" width=\"160\"/>\n",
      "</div>\n",
      "\n",
      "\n",
      "<div class=\"text_area\">\n",
      "<strong class=\"title\">‘월드컵 조추첨 D-2’ 가상 결과는 어떨까? ‘한국 최악의 조’</strong>\n",
      "<!-- [D] 내용 두줄 말줄임 적용해주세요. -->\n",
      "<p class=\"news\">\n",
      "\t\t\t\t\t\t\t\t가상 월드컵 조주첨. 사진=더 선 캡처[동아닷컴]대망의 월드컵 조추첨이 이틀 앞으로 다가온 가운데, 영국의 한 매체가 가상의 조추첨 결과를 내놨다. 한국은 ...\n",
      "\t\t\t\t\t\t</p>\n",
      "<div class=\"information\">\n",
      "<span>스포츠동아</span>\n",
      "<span>대표팀</span>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "\n",
      "젠지로 새로 합류한 스트리머 정예지 \"올해 목표, 롤 다이아 달성하겠다\" [인터뷰]\n",
      "\n",
      "\n",
      "<div class=\"image_area\">\n",
      "<!-- [D] 썸네일 이미지 alt 값 비워주세요. -->\n",
      "<img alt=\"\" height=\"95\" onerror=\"imageOnError(this);\" src=\"https://dthumb-phinf.pstatic.net?src=http://imgnews.naver.net/image/311/2022/03/31/0001427735_001_20220331154601522.jpg&amp;type=nf160_95&amp;service=sports\" width=\"160\"/>\n",
      "</div>\n",
      "\n",
      "\n",
      "<div class=\"text_area\">\n",
      "<strong class=\"title\">젠지로 새로 합류한 스트리머 정예지 \"올해 목표, 롤 다이아 달성하겠다\" [인터뷰]</strong>\n",
      "<!-- [D] 내용 두줄 말줄임 적용해주세요. -->\n",
      "<p class=\"news\">\n",
      "\t\t\t\t\t\t\t\t(엑스포츠뉴스 최지영기자) '지켜봐주고 나쁘게만 보지 않았으면 좋겠다\"미국 젠지는 3월 한 달을 여성의 달로 지정하며 다양한 활동을 진행했다...\n",
      "\t\t\t\t\t\t</p>\n",
      "<div class=\"information\">\n",
      "<span>엑스포츠뉴스</span>\n",
      "<span>e스포츠 일반</span>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#url_n = \"http://www.naver.com\"\n",
    "url_n_sel = \"https://sports.news.naver.com/index\"\n",
    "#url_d = \"http://www.daum.net\"\n",
    "#url_y = \"http://www.yahoo.com\"\n",
    "\n",
    "#resp_n = urllib.request.urlopen(url_n)\n",
    "resp_n_sel = urllib.request.urlopen(url_n_sel)\n",
    "#resp_d = urllib.request.urlopen(url_d)\n",
    "#resp_y = urllib.request.urlopen(url_y)\n",
    "\n",
    "#data_n = resp_n.read()\n",
    "data_n_sel = resp_n_sel.read()\n",
    "#data_d = resp_n.read()\n",
    "#data_y = resp_n.read()\n",
    "\n",
    "#html_n = data_n.decode(\"utf-8\")  \n",
    "src_n_sel = data_n_sel.decode(\"utf-8\")    \n",
    "#html_d = data_d.decode(\"utf-8\")\n",
    "#html_y = data_y.decode(\"utf-8\")\n",
    "\n",
    "#soup_n = BeautifulSoup(html_n,\"html.parser\")  \n",
    "html_n_sel = BeautifulSoup(src_n_sel,\"html.parser\")    \n",
    "#soup_d = BeautifulSoup(html_d,\"html.parser\")\n",
    "#soup_y = BeautifulSoup(html_y,\"html.parser\")\n",
    "\n",
    "# li태그 목록 불러오기\n",
    "# li_n = soup_n.find_all('li')\n",
    "# for li in li_n:\n",
    "#     print(li.string)\n",
    "# li_d = soup_d.find_all('li')\n",
    "# for li in li_d:\n",
    "#     print(li.string)\n",
    "# li_y = soup_y.find_all('li')\n",
    "# for li in li_y:\n",
    "#     print(li.string)\n",
    "\n",
    "# 주요기사 내용 출력\n",
    "# class = link_today\n",
    "atags = html_n_sel.select('a[class=link_today]')\n",
    "print('atags 수 = ',len(atags))\n",
    "for a in atags:\n",
    "    print(a.attrs['title'])\n",
    "    for td in a:\n",
    "        print(td)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
